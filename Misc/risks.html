<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>risks</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>

<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home page</a>
  <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="misc/risks.html">Risks</a>
	<li><a href="choices.html">Choices</a>
	<li><a href="ethics.html">Ethical Reflections</a>
	<li><a href="references.html">References</a>
   <li><a href="process.html">Process Support</a>
</ul>

<!-- Main content -->
<h1>Technology Risks</h1>

</ul><h3><p>Echo Chambers<p></h3>
</ul><h4><p>An echo chamber is a metaphor an online space that affirms a person’s beliefs because they are surrounded only by people of the same opinions. Online spaces like this reinforce opinions and filter out challenging opinions, people are drawn to these places by an algorithm’s tendency on social media websites to filter like-minded people together. (Kitchens et al., 2020, p. 1619) One risk posed by Echo Chambers is the tendency over time for users’ opinions to become far more, as an example, in recent years the number of people that believe you cannot be racist to a white person has increased. Even though the definition of the word ‘racism’ by dictionary.com is:<br><br>
	A belief or doctrine that inherent differences among the various human racial groups determine cultural or individual achievement, usually involving the idea that one's own race is superior and has the right to dominate others or that a particular racial group is inferior to the others. (Dictionary.com, n.d.)<br><br>
Due to the prevalence of social media in society today the amount of people expressing extreme beliefs such as that has increased, these are the effects of an echo chamber, people’s beliefs are never challenged, only reinforced over time. Due to the reinforcing of beliefs, people with even more extreme opinions are affirmed and the group slowly becomes more extreme. Another example of an echo chamber leading to extreme beliefs and action is the January 6th Capitol Riot in the aftermath of the 2020 US Presidential Election. Due to online Echo Chambers the belief that the election was fraudulent was able to sustain itself amongst a crowd of right-wing radicals. This all culminated on January 6th when a large group invaded the Capitol building to protest the results of the now decided election. An Echo Chamber was a large reason why many people continued to believe this, the website 4Chan which is predominantly used by people with right-wing political beliefs was the staging ground for misinformation about the election results, which then spread to private groups on Facebook, Twitter and YouTube, creating small Echo Chambers that served to further radicalize their users. After this it becomes next-to impossible to shut down misinformation and once it becomes big enough an incident like January 6th is the result. To conclude, the usage of social media is actively risking the user falling into an Echo Chamber. This is dangerous because people on both sides of the political spectrum are pushed further apart and radicalized. It becomes much harder to have a productive discourse with people of opposing beliefs as they are so firmly entrenched in what they believe.
.<p></h4>
</ul><h3><p>Censorship<p></h3>
</ul><h4><p>One risk of social media and the internet is that it is liable to interference from world governments looking to remove information or push a particular agenda, as well as private companies deciding what they would like shared. Government censorship of social media can become a problem during election season and when a particular piece of information or story surfaces. One such example of government censorship is the removal of posts on Chinese social media website Weibo that supported the Free Hong Kong movement, despite this there is still plenty of time for people to express dissatisfaction of the government of criticisms before the authorities can react and censor. (Liu & Zhao, 2021, p. 3.3) Weibo has over 130 million users, therefore it is a space of huge visibility on the Chinese internet and material can be spread faster then it can be removed. This leads to the question, how fast do governments need to act before something has spread too far? One case of content removal  that received widespread attention was the March 15th Christchurch mosque attacks, which were livestreamed on Facebook and subsequently reuploaded to multiple corners of the internet. The initial livestream received 4000 viewers in it’s first hour alone. (Kampmark, 2019) Should the private companies involved acted faster to remove the livestream before it reached that many viewers? Well, it is complicated, due to the automated algorithms that police content on social media, grossly violent and rule-breaking content is often missed. This is because it first must be detected or reported, then reviewed, usually by an algorithm and a person second. An algorithm can easily scan text and filter or block content, however, how can an algorithm effectively and quickly remove a video such as the livestream of the Marth 15th attacks. A free and open internet is taking a risk that material of obscene and gross nature will find it is way into mainstream public eye, material such as the March 15th attacks, should the government and companies do more to censor the Internet to prevent the spread of such material? Or would that be an attack on freedom of speech and the ability to express yourself online? It is a tricky balancing act of how much should be allowed on the internet and how much should not. <p></h4>
</ul><h3><p>Misinformation and Disinformation<p></h3>
</ul><h4><p>One risk that social media poses is the blatant spread of false or misleading information (misinformation), due to the nature of websites like Facebook and Twitter people can post or re-post whatever they choose to. Often false news is created for financial or political gain, due to the consumption of fake news a persons trust in real news sources is eroded over time.(Shu et al., 2020, p. 2) Intentionally spreading false information (disinformation) is innate to the internet, the degree to which people will spread this kind of information is usually determined by a particular motivation, financial, political or comedic in nature. The least malicious kind of disinformation would be shared to get a reaction out of other users, ranging from disbelief or anger. The most malicious kind of information shared would be false information that tries to convince users of its truthfulness. Financial reasons to spread disinformation could include bribes from government entities, or financial gain from the spread of such information. One such risk posed by this is the ability for social media companies to spread disinformation on their own platforms about other companies, driving them out of the market and enabling the big companies to keep a monopoly on the space. Political motivations for spreading disinformation are the ability to damage an opponents’ campaign, by convincing enough people of something false you increase your own reputation in their eyes. Misinformation is spread by people who have no malicious intent, which raises the problem that intentionally spread fake news can become organically spread by people believing it to be true. Social media is the largest space for the organic growth of misinformation, the risks this poses to society are huge, some of those include. People no longer having trust in news, political rivals spreading information to damage each other, companies forcing other companies out of the markets and people being convinced of false things.<p></h4>
</ul><h3><p>Anonymity<p></h3>
</ul><h4><p>One risk posed by social media is the ability for someone on the other side of the world to find your personal information, for companies to harvest and sell your data and for data to be leaked in huge data breaches. Being anonymous online has great advantages, to speak anonymously is to speak freely, without fear of retribution or punishment for your words. On the internet today most websites require you to sign in and provide some real information about you, this restricts what you can say due to the fear of people finding your information. Some websites exist as entirely anonymous platforms such as 4Chan where the only rules are against illegal content, these websites have their benefits as people living in countries with more internet monitoring can still express their opinions. Websites like Twitter and Facebook that require partial information about a person can still be made semi-anonymous with private profiles. However, they are still liable to data breaches where user’s personal information is visible, often a breach will result in many users accounts being made vulnerable without their knowledge. Or, their personal information is leaked to the public, this could be a problem for people with outspoken ideas or socially  unacceptable opinions. A data breach can make them targets, these are the upsides of anonymity, they protect people from harassed and vilified for what they say. The downsides to anonymity, however, is much harder for authorities to catch people breaking the law, there is often little to no consequences for a user’s online actions. Being anonymous online implicitly encourages people to try and do things they would not normally do, such as bully and harass other users, spread misinformation / disinformation and engage in illegal activities. Ultimately anonymity is an important part of the internet, some websites  work better with it, others without. .<p></h4>

<!-- Sign and date the page, it's only polite! -->
<address>Made 4 June 2021<br>
  by Jack Briggs.</address>
 
<p><em>thanks to W3C for tutorial and adapted code from <a href="https://www.w3.org/Style/Examples/011/firstcss.en.html">Style Examples</a></p></em>
<p><em>also thanks to WDN for HTML and CSS resources and any adapted code snippets from <a href= "https://developer.mozilla.org/en-US/docs/Web">Mozilla Developer Network</a></p></em 
 </html>
